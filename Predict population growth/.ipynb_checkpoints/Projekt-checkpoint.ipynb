{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f46dc6-0717-478f-9e7c-53b381afbffc",
   "metadata": {},
   "source": [
    "# Projekt moduÅ‚Ã³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25df3de3-2fde-4ce0-9668-23eb6ed65b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec95420-1667-4233-979a-20b0fd94a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_regression(n_j=2):\n",
    "    lr = LinearRegression(n_jobs=n_j)\n",
    "    return lr\n",
    "\n",
    "def create_decision_tree_regressor(depth,min_split,spliter = 'best'):\n",
    "    dt = DecisionTreeRegressor(max_depth=depth,min_samples_split=min_split,splitter=spliter,random_state=0)\n",
    "    return dt\n",
    "\n",
    "def create_random_forest_regressor(depth, number_tree=100, criterion=\"squared_error\", n_j=2):\n",
    "    rfr = RandomForestRegressor(n_estimators=number_tree,max_depth=depth,criterion=criterion,n_jobs=n_j,random_state=0)\n",
    "    return rfr\n",
    "\n",
    "def create_XGBR(number_tree=250,learn_rate=0.01,tree_met=\"hist\"):\n",
    "    xgb = XGBRegressor(n_estimator=number_tree,learning_rate=learn_rate,tree_method=tree_met,random_state=0)\n",
    "    return xgb\n",
    "\n",
    "def create_KNNR(nn=3,weight='uniform',n_j=4):\n",
    "    knn = KNeighborsRegressor(n_neighbors=nn,weights=weight,n_jobs=n_j)\n",
    "    return knn\n",
    "\n",
    "def create_nn(number_hiden_layers=2,dense=[128,64],loss='mean_absolute_error',\n",
    "              learning_rate=0.001,\n",
    "              metrics=[tf.keras.metrics.MeanSquaredError(name='mean_squared_error'),\n",
    "                       tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_errorasawewa')],\n",
    "              input_shape=(16,)):\n",
    "                           model = tf.keras.Sequential()\n",
    "                           model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "                           for i in range(number_hiden_layers):\n",
    "                               model.add(tf.keras.layers.Dense(dense[i], activation='relu'))\n",
    "                               \n",
    "                           model.add(tf.keras.layers.Dense(1))\n",
    "                           model.compile(\n",
    "                               loss=loss,\n",
    "                               optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                               metrics=metrics\n",
    "                           )\n",
    "                           return model\n",
    "\n",
    "def read_dataset(number: int):\n",
    "    data = pd.read_csv('./Data/DataSets/DataSet' + str(number) + '.csv')\n",
    "    data\n",
    "    return data\n",
    "\n",
    "def is_null(data):\n",
    "    is_nan = data.isnull().sum()\n",
    "    print(is_nan)\n",
    "\n",
    "def heatmap(data):\n",
    "    corr = data.corr()\n",
    "    mask = np.triu(np.ones_like(corr,dtype=bool))\n",
    "    f,ax = plt.subplots(figsize=(11,9))\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    sns.heatmap(corr,mask=mask,cmap=cmap,center=0,vmax=0.8,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()\n",
    "\n",
    "def describe_data(data):\n",
    "    des = data.describe()\n",
    "    display(des)\n",
    "\n",
    "def prepare_data_to_train(data):\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data['Population']\n",
    "    return X,y\n",
    "\n",
    "def split_to_train_test(X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def cross_val_fit(model, X, y,metrics ,cv=5):\n",
    "    cv_score = cross_validate(model, X, y, cv=cv,scoring=metrics)\n",
    "    test_metrics = [x for x in cv_score if x.startswith('test')]\n",
    "    for k in range(cv):\n",
    "        print(f'Metrics in {k+1}-fold:')\n",
    "        for metric in test_metrics:\n",
    "            print(f'{metric.split(\"test_\")[1]}: {cv_score[metric][k]:.2f}')\n",
    " \n",
    "def nn_fit(model, X_train, X_test, y_train, y_test, n_epoch):\n",
    "    model.fit(X_train, y_train, epochs=n_epoch, validation_data=(X_test,y_test))\n",
    "    metric = model.evaluate(X_test,y_test,return_dict=True)\n",
    "    print(metric)\n",
    "\n",
    "def select_problem():\n",
    "    try:\n",
    "        problem = int(input('''\n",
    "        Select which type of problem from 1 to 3:\n",
    "        1. Regression\n",
    "        2. Classification\n",
    "        3. Clustering\n",
    "        '''))\n",
    "        if problem == 1:\n",
    "            return problem\n",
    "        elif problem > 1 and problem<=3:\n",
    "            print('To be added in the future')\n",
    "            select_problem()\n",
    "        else:\n",
    "            print('Please select number from 1 to 3')\n",
    "            select_problem()\n",
    "    except ValueError:\n",
    "        print('Wrong type. Please select number from 1 to 3')\n",
    "        select_problem()\n",
    "\n",
    "def select_data():\n",
    "    try:\n",
    "        n_dataset = int(input('Select dataset 1 to 14 (description of data sets in the documentation): '))\n",
    "        if n_dataset>0 and n_dataset<=14:\n",
    "            dataset = read_dataset(n_dataset)\n",
    "            return dataset\n",
    "        else:\n",
    "            print('Please select number from 1 to 14')\n",
    "            select_data()\n",
    "    except ValueError:\n",
    "        print('Wrong type. Please select number from 1 to 14')\n",
    "\n",
    "def visualiztaion_data_module(data):\n",
    "    visual_input = ''\n",
    "    while visual_input != 'stop':\n",
    "        visual_input = input('''\n",
    "        Select one option from below or write \"stop\" to end visualization module:\n",
    "        1.Heatmap -> plot heat map\n",
    "        2.Isnull -> is NaN value\n",
    "        3.Describe data set \n",
    "        ''').lower()\n",
    "        match visual_input :\n",
    "            case 'heatmap' | '1':\n",
    "                heatmap(data)\n",
    "            case 'isnul' | '2':\n",
    "                is_null(data)\n",
    "            case 'describe' | '3':\n",
    "                describe_data(data)\n",
    "            case 'stop':\n",
    "                print('Ending visualiztion module')\n",
    "            case _:\n",
    "                print('Wrong choice')\n",
    "\n",
    "def check_param_num_float(min_val,max_val):\n",
    "    try:\n",
    "        x = float(input(f'Write float value between {min_val} and {max_val} (value with \".\" instead \",\")'))\n",
    "        if x>=min_val and x<=max_val :\n",
    "            return x\n",
    "        else:\n",
    "            print('Wrong range')\n",
    "            check_parm_num(min_val,max_val)\n",
    "    except ValueError:\n",
    "        print('Wrong type')\n",
    "        check_parm_num(min_val,max_val)\n",
    "\n",
    "\n",
    "def check_param_num_int(min_val,max_val):\n",
    "    try:\n",
    "        x = int(input(f'Write integer value between {min_val} and {max_val}'))\n",
    "        if x>=min_val and x<=max_val :\n",
    "            return x\n",
    "        else:\n",
    "            print('Wrong range')\n",
    "            check_parm_num(min_val,max_val)\n",
    "    except ValueError:\n",
    "        print('Wrong type')\n",
    "        check_parm_num(min_val,max_val)\n",
    "\n",
    "def check_param_str(params):\n",
    "    print('Select one from below:')\n",
    "    for param in params:\n",
    "        print(param)\n",
    "    x = input('Write: ').lower()\n",
    "    if x in params:\n",
    "        return x\n",
    "    else:\n",
    "        print('Wrong choice')\n",
    "        check_param_str(params)\n",
    "\n",
    "def model_selection(X):\n",
    "    choose_model = input('''\n",
    "    Choose from the following models:\n",
    "    1. Decision tree\n",
    "    2. Random forest\n",
    "    3. kNN\n",
    "    4. Linear regression\n",
    "    5. XGBR\n",
    "    6. Neural network \n",
    "    ''').lower()\n",
    "    is_nn = 0\n",
    "    match choose_model:\n",
    "        case 'decision tree' | '1':\n",
    "            decision = input('Do you want to use a predefined model: Yes or No ').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_decision_tree_regressor(int(X.shape[0]/2),2,'best')\n",
    "                return model, is_nn\n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select max depth of tree')\n",
    "                depth  = check_param_num_int(2,X.shape[0])\n",
    "                print('Select minimum number of samples')\n",
    "                min_split = check_param_num_int(2,int(X.shape[0]))\n",
    "                print('Choose the split at each node')\n",
    "                spliter = check_param_str(['best', 'random'])\n",
    "                model = create_decision_tree_regressor(depth,min_split,spliter)\n",
    "                return model, is_nn\n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case 'random forest' | '2':\n",
    "            decision = input('Do you want to use a predefined model: Yes or No ').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_random_forest_regressor(int(X.shape[0]/2))\n",
    "                return model, is_nn\n",
    "                \n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select max depth of trees')\n",
    "                depth = check_param_num_int(2,X.shape[0])\n",
    "                print('Select number of trees in the forest')\n",
    "                number_tree = check_param_num_int(50,500)\n",
    "                print('Select criterion')\n",
    "                criterion= check_param_str(['squared_error', 'absolute_error', 'friedman_mse', 'poisson'])\n",
    "                print('Select number of jobs to run in parallel')\n",
    "                n_j = check_param_num_int(1,8)\n",
    "                model = create_random_forest_regressor(depth,number_tree,criterion,n_j)\n",
    "                return model, is_nn\n",
    "                \n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case 'knn' | '3':\n",
    "            decision = input('Do you want to use a predefined model: Yes or No ').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_KNNR()\n",
    "                return model, is_nn\n",
    "                \n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select number of neighbors')\n",
    "                nn = check_param_num_int(3,50)\n",
    "                print('Select weight function used in prediction')\n",
    "                weight = check_param_str(['uniform', 'distance'])\n",
    "                print('Select number of jobs to run in parallel')\n",
    "                n_j = check_param_num_int(1,8)\n",
    "                model = create_KNNR(nn,weight,n_j)\n",
    "                return model, is_nn\n",
    "                \n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case 'linear regression' | '4':\n",
    "            decision = input('Do you want to use a predefined model: Yes or No ').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_linear_regression()\n",
    "                return model, is_nn\n",
    "                \n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select number of jobs to run in parallel')\n",
    "                n_j = check_param_num_int(1,8)\n",
    "                model = create_linear_regression(n_j)\n",
    "                return model, is_nn\n",
    "                \n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case 'XGBR' | '5':\n",
    "            decision = input('Do you want to use a predefined model: Yes or No ').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_XGBR()\n",
    "                return model, is_nn\n",
    "                \n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select max depth of trees')\n",
    "                number_tree = check_param_num_int(50,500)\n",
    "                print('Select learning rate')\n",
    "                learn_rate = check_param_num_float(0,1)\n",
    "                print('Select tree method')\n",
    "                tree_met = check_param_str(['exact', 'approx', 'hist'])\n",
    "                model = create_XGBR(number_tree,learn_rate,tree_met)\n",
    "                return model, is_nn\n",
    "                \n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case 'neural network' | '6':\n",
    "            is_nn = 1\n",
    "            decision = input('Do you want to use a predefined model: Yes or No').lower()\n",
    "            \n",
    "            if decision == 'yes' or decision =='y':\n",
    "                model = create_nn(2,[128,64],'mean_absolute_error',0.001,\n",
    "                          [tf.keras.metrics.MeanSquaredError(name='mean_squared_error'),tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error')],\n",
    "                          X.shape[1])\n",
    "                return model, is_nn\n",
    "                \n",
    "            elif decision == 'no' or decision =='n':\n",
    "                print('Select the number of hidden layers')\n",
    "                hiden = check_param_num_int(1,10)\n",
    "                dense = []\n",
    "                \n",
    "                for i in range(hiden):\n",
    "                    print(f'Select number of neurons in {i+1} hiden layer')\n",
    "                    num_neurons = check_param_num_int(2,1024)\n",
    "                    dense.append(num_neurons)\n",
    "                    \n",
    "                loss_func = check_param_str(['mean_absolute_error','mean_squared_error','root_mean_squared_error'])\n",
    "                \n",
    "                print('Select learning rate')\n",
    "                learn_rate = check_param_num_float(0,1)\n",
    "                \n",
    "                metrics = metrics_for_train(['mean_absolute_error','mean_squared_error','root_mean_squared_error'])\n",
    "                model = create_nn(hiden,dense,loss_func,learn_rate,metrics,X.shape[1])\n",
    "                return model, is_nn\n",
    "                \n",
    "            else:\n",
    "                print('Wrong answer')\n",
    "                model_selection(X,y)\n",
    "                \n",
    "        case _:\n",
    "            print('Wrong choice')\n",
    "            model_selection(X)\n",
    "\n",
    "def metrics_for_train(metric_acc):\n",
    "    metric = ''\n",
    "    metrics = []\n",
    "    i = 0 \n",
    "    while (metric != 'stop'):\n",
    "        if i == len(metric_acc):\n",
    "            break\n",
    "        print('''\n",
    "        Select metrics from below or stop \n",
    "        ''')\n",
    "        for m in metric_acc:\n",
    "            print(m)\n",
    "\n",
    "        metric= input()\n",
    "        if metric in metrics:\n",
    "            print('Please choose a different metric')\n",
    "        elif metric in metric_acc:\n",
    "            if metric == 'root_mean_squared_error':\n",
    "                metrics.append(tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error'))\n",
    "            else:\n",
    "                metrics.append(metric)\n",
    "                i+=1\n",
    "        elif metric == 'stop' and len(metrics)!=0:\n",
    "            print('End of choice of metrics')\n",
    "        elif metric == 'stop' and len(metrics)==0:\n",
    "            print('You must choose one metric')\n",
    "        else:\n",
    "            print('Wrong choice')\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def trening_models(model,X,y):\n",
    "    print('Specify the number of k-folds in cross-validation')\n",
    "    cv = check_param_num_int(1,20)\n",
    "    metrics = metrics_for_train(['max_error','neg_mean_absolute_error','neg_mean_squared_error','neg_root_mean_squared_error'])\n",
    "    if len(metrics)>1:\n",
    "        cross_val_fit(model,X,y,metrics=metrics,cv=cv)\n",
    "    else: \n",
    "        cross_val_fit(model,X,y,metrics[0],cv)\n",
    "\n",
    "def trening_nn(model,X,y):\n",
    "    print('Define what percentage will be test data, where 0.2 equals 20%: ')\n",
    "    test_size = check_param_num_float(0,1)\n",
    "    X_train, X_test, y_train, y_test = split_to_train_test(X,y,test_size)\n",
    "    print('How many epochs the neural network has to learn')\n",
    "    n_epochs = check_param_num_int(1,1000)\n",
    "    nn_fit(model, X_train, X_test, y_train, y_test, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb5cc5d-b6b9-480c-83ee-7dcfa49cf012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start function\n",
    "def start_modules():\n",
    "    print('Start AI project')\n",
    "    slected_problem = select_problem()\n",
    "    dataset = select_data()\n",
    "    visualiztaion_data_module(dataset)\n",
    "    X,y = prepare_data_to_train(dataset)\n",
    "    is_continue = ''\n",
    "    while is_continue != 'no':\n",
    "        model,is_nn = model_selection(X)\n",
    "        if is_nn == 0:\n",
    "            trening_models(model,X,y)\n",
    "            print('Do you want to try a different model')\n",
    "            is_continue = check_param_str(['yes','no'])\n",
    "        elif is_nn == 1:\n",
    "            trening_nn(model,X,y)\n",
    "            print('Do you want to try a different model')\n",
    "            is_continue = check_param_str(['yes','no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8067054e-7e75-4c7f-a486-d26fd8326ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start AI project\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "        Select which type of problem from 1 to 3:\n",
      "        1. Regression\n",
      "        2. Classification\n",
      "        3. Clustering\n",
      "         1\n",
      "Select dataset 1 to 14 (description of data sets in the documentation):  5\n",
      "\n",
      "        Select one option from below or write \"stop\" to end visualization module:\n",
      "        1.Heatmap -> plot heat map\n",
      "        2.Isnull -> is NaN value\n",
      "        3.Describe data set \n",
      "         stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending visualiztion module\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    Choose from the following models:\n",
      "    1. Decision tree\n",
      "    2. Random forest\n",
      "    3. kNN\n",
      "    4. Linear regression\n",
      "    5. XGBR\n",
      "    6. Neural network \n",
      "     a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong choice\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    Choose from the following models:\n",
      "    1. Decision tree\n",
      "    2. Random forest\n",
      "    3. kNN\n",
      "    4. Linear regression\n",
      "    5. XGBR\n",
      "    6. Neural network \n",
      "     1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstart_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m, in \u001b[0;36mstart_modules\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m is_continue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m is_continue \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     model,is_nn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_nn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     12\u001b[0m         trening_models(model,X,y)\n",
      "Cell \u001b[1;32mIn[5], line 321\u001b[0m, in \u001b[0;36mmodel_selection\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrong choice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 321\u001b[0m     \u001b[43mmodel_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 186\u001b[0m, in \u001b[0;36mmodel_selection\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m choose_model:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision tree\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 186\u001b[0m         decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDo you want to use a predefined model: Yes or No \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m decision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m decision \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    189\u001b[0m             model \u001b[38;5;241m=\u001b[39m create_decision_tree_regressor(\u001b[38;5;28mint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "start_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f6aaa-653a-4a47-bc4d-83c7ab423972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
